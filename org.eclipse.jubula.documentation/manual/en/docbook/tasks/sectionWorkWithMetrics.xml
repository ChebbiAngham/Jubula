<section id="working-with-metrics" version="5.0" xmlns="http://docbook.org/ns/docbook"
                                                 xmlns:xi="http://www.w3.org/2001/XInclude"
                                                 xmlns:xl="http://www.w3.org/1999/xlink" >
  <title>Working with Metrics</title>
  <para>
    The Analysis framework lets you run metrics on your Project. In
    the current version, three example metrics are included which can
    be run on the whole Project or on parts of it.
  </para>
  <para>
    The analyses and metrics can either be run for the whole Project,
    or for specific contexts within the Project.
  </para>
  <para>
    To run a metric or analysis for the whole Project, select the
    metric or analysis you want to perform from the toolbar button.
  </para>
  <para>
    To run a metric or analysis for a specific context, select the context you require (e.g. the top node in the Test Case Browser to perform the metric or analysis just for items within this browser) and then select:
    
    <para>
      <emphasis role="menuPath">Analyze</emphasis>
    </para>
      
    from the context menu, selecting the required option to run.
  </para>
  <para>
    Once a metric or analysis has run, the results are shown in the
    Search Result View.
  </para>
  <para>
    The following metrics and analyses are available:
  </para>
  <section id="numeric-project-element-counter">
    <title>Numeric Project Element Counter</title>
    <para>
      This metric is in the category <emphasis>Numerical
      Metrics</emphasis>.
    </para>
    <para>
      This metric counts the amount of items in a Project according to
      the following rules:
    </para>
    <variablelist>
      <varlistentry>
        <term>
          Test Cases:
        </term>
        <listitem>
          <para>
            How many individual Test Cases have been created.
          </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          Test Suites:
        </term>
        <listitem>
          <para>
            How many individual Test Suites have been created.
          </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          Test Jobs:
        </term>
        <listitem>
          <para>
            How many individual Test Jobs have been created.
          </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          Test Steps:
        </term>
        <listitem>
          <para>
            How many individual Test Steps have been created, plus how
            many Test Steps have been used from any reused Projects.
            Test Steps are only counted once for the place they are
            specified (or, in the case of Test Steps from reused
            Projects, reused). They are not counted transitively (i.e.
            if a Project contains a Test Case with one Test Step, and
            this Test Case is reused four times, there is still only
            one Test Step.
          </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          Referenced Test Cases:
        </term>
        <listitem>
          <para>
            How many separate (not transitive) Test Case references
            there are in the current scope. If a Test Case
            <emphasis>TC1</emphasis> is reused twice in a Test Case
            <emphasis>TC2</emphasis>, then the number of reuses for
            <emphasis>TC1</emphasis> is two, regardless of how many
            times <emphasis>TC2</emphasis> is reused.
          </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          Event Handlers:
        </term>
        <listitem>
          <para>
            How many Event Handlers are used in the current scope. The
            same rules for non-transitivity apply - if
            <emphasis>TC1</emphasis> contains an Event Handler, then
            this Event Handler is only counted once, regardless how
            many times <emphasis>TC1</emphasis> is reused.
          </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          Categories:
        </term>
        <listitem>
          <para>
            How many categories are created in the current scope. Only
            categories in the Test Case Browser and Test Suite Browser
            are currently counted.
          </para>
        </listitem>
      </varlistentry>
    </variablelist>
    <para>
      The results are shown in the Search Result View.
    </para>
  </section>
  <section id="ratio-general-specific">
    <title>Ratio general : specific</title>
    <para>
      This metric is in the category <emphasis>Numerical
      Metrics</emphasis>.
    </para>
    <para>
      This metric calculates the amount of Test Cases or Test Steps
      used that are generally available for all
      <emphasis>toolkits</emphasis> (the
      ”<emphasis>concrete</emphasis>” actions). It then counts the
      amount of actions used that are specific to one or more
      particular toolkits (e.g. specific to the RCP toolkit or the
      HTML toolkit). The results are presented as percentages in the
      Search Result View.
    </para>
    <para>
      Wherever possible, it is preferable to work with more general
      actions than specific. This metric may help you to gauge how
      well you are keeping to this guideline.
    </para>
  </section>
  <section id="empty-chains-analysis">
    <title>Empty chains analysis</title>
    <para>
      This analysis is in the category <emphasis>Analysis</emphasis>.
    </para>
    <para>
      This analysis examines the current scope for test hierarchies
      wherein a Test Case is reused in one place – alone in another
      Test Case. This Test Case is then also reused in one place –
      again alone which is then reused in one place alone in another
      Test Case and so on. Such hierarchies can often be redundant:
      the Test Case at the bottom of the hierarchy could just as well
      have been reused directly in the Test Case at the top of the
      hierarchy.
    </para>
    <para>
      Such empty chains are collected during the analysis (which may
      take longer on larger Projects) and displayed in the Search
      Result View. They are shown in order of their length, starting
      with the longest chains.
    </para>
  </section>
  <section id="waits-and-delays">
    <title>Waits and delays</title>
    <para>
      This analysis can be performed on Test Result Reports in the Execution Perspective and in the Reporting Perspective. Select a node you want to analyze and select:
      
      <para>
        <emphasis role="menuPath">Analyze</emphasis>--&gt;<emphasis role="menuPath">Waits and delays</emphasis>
      </para>
      
      from the context-sensitive menu.
    </para>
    <para>
      The analysis examines the selected node and the nodes below it
      in the Test Result Report for all instances where a wait is
      performed. This can be the action ”<emphasis>Wait</emphasis>” or
      it could also be the parameters ”<emphasis>Delay
      after...</emphasis>” or ”<emphasis>Delay before...</emphasis>”.
      Basically, any time a static wait (i.e. not a timeout) is
      performed, then this is analyzed.
    </para>
    <para>
      You can define a parameter for the analysis which specifies the
      minimum value of waits to be analyzed (in milliseconds). If you
      enter e.g. 5000, then only waits above 5000ms will be shown in
      the results.
    </para>
    <para>
      Once the results have been calculated, they are shown in the
      Search Result View. They are organized according to the action
      that the wait is contained in. The amount of waits corresponding
      to each action is shown in brackets behind the action name. On
      the right hand side of the Search Result View, the cumulative
      values for the amount of waits for each action are shown. The
      number on the left is the total amount of waits that correspond
      to the parameter value entered. The number on the right shows
      the total amount of waits for this action, regardless of the
      parameter. In this way, it is easier to see whether your tests
      have a few very large waits, or many smaller waits.
    </para>
    <para>
      <para role="tip">Double click on one of the wait actions to jump to this
      place in the test Result View.</para>
    </para>
  </section>
</section>